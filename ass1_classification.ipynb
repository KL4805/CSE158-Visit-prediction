{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import gzip\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import sklearn.decomposition\n",
    "\n",
    "\n",
    "def readGz(f):\n",
    "  for l in gzip.open(f):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for l in readGz('train.json.gz'):\n",
    "    data.append(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "userList = []\n",
    "businessList = []\n",
    "userDict = defaultdict(int)\n",
    "businessDict = defaultdict(int)\n",
    "visitedDict = defaultdict(int)\n",
    "for d in data:\n",
    "    u = d['userID']\n",
    "    b = d['businessID']\n",
    "    if u not in userList:\n",
    "        userList.append(u)\n",
    "    if b not in businessList:\n",
    "        businessList.append(b)\n",
    "    visitedDict[(u,b)]+=1\n",
    "\n",
    "    \n",
    "for i in range(len(userList)):\n",
    "    userDict[userList[i]] = i\n",
    "for i in range(len(businessList)):\n",
    "    businessDict[businessList[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.18719375\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(data)\n",
    "train_data = data[:160000]\n",
    "\n",
    "validation_data = data[160000:200000]\n",
    "negative_pair = []\n",
    "randomCnt = 0\n",
    "while(randomCnt) < 80000:\n",
    "    ruIndex = random.randint(0, len(userList)-1)\n",
    "    rbIndex = random.randint(0, len(businessList)-1)\n",
    "    ru = userList[ruIndex]\n",
    "    rb = businessList[rbIndex]\n",
    "    if visitedDict[(ru, rb)]==0:\n",
    "        randomCnt +=1\n",
    "        negative_pair.append((ru,rb))\n",
    "#Finished creating dataset\n",
    "\n",
    "ratings = np.array([d['rating'] for d in train_data])\n",
    "avgRating = np.mean(ratings)\n",
    "print avgRating\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mean(lst):\n",
    "    if len(lst) != 0:\n",
    "        return np.mean(lst)\n",
    "    else:\n",
    "        return avgRating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.333333333333333, 4.375, 4.2127659574468082, 4.2857142857142856, 3.828125, 4.5625, 4.375, 5.0, 4.4545454545454541, 4.2000000000000002, 4.3250000000000002, 4.75, 3.7000000000000002, 4.333333333333333, 3.6818181818181817, 4.2999999999999998, 3.5, 4.1111111111111107, 4.125, 3.2142857142857144]\n"
     ]
    }
   ],
   "source": [
    "businessRat = [[] for i in range(len(businessList))]\n",
    "for d in train_data:\n",
    "    businessRat[businessDict[d['businessID']]].append(d['rating'])\n",
    "businessAvg = [Mean(businessRat[i]) for i in range(len(businessList))]\n",
    "print businessAvg[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoryList = []\n",
    "for d in train_data:\n",
    "    for c in d['categories']:\n",
    "        if c not in categoryList:\n",
    "            categoryList.append(c)\n",
    "categoryDict = defaultdict(int)\n",
    "for c in categoryList:\n",
    "    categoryDict[c] = categoryList.index(c)\n",
    "\n",
    "businessCategory = [[0 for j in range(len(categoryList))] for i in range(len(businessList))]\n",
    "userHistory = [[0 for j in range(len(categoryList))] for i in range(len(userList))]\n",
    "for d in train_data:\n",
    "    for c in d['categories']:\n",
    "        userHistory[userDict[d['userID']]][categoryDict[c]]+=1.0\n",
    "        businessCategory[businessDict[d['businessID']]][categoryDict[c]]=1\n",
    "#the list of what each business's category is and what category each user has visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    feat = []\n",
    "    userOneHot = [0 for u in userList]\n",
    "    businessOneHot = [0 for b in businessList]\n",
    "    userOneHot[userDict[datum['userID']]] = 1\n",
    "    businessOneHot[businessDict[datum['businessID']]] = 1\n",
    "    feat.append(np.array(userOneHot))\n",
    "    feat.append(np.array(businessOneHot))\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting features and ratings\n",
    "\n",
    "train_rating = [d['rating'] for d in train_data]\n",
    "\n",
    "validation_rating = [d['rating'] for d in validation_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorflow learning hyper parameters\n",
    "learning_rate = 0.001\n",
    "regularization_rate = 0.001\n",
    "Reduction_Size = 100\n",
    "max_iter = 20000\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(user, business, regularizer):\n",
    "    predict = avgRating\n",
    "    with tf.variable_scope('bu'):\n",
    "        betau = tf.get_variable(name = 'betau', shape = [len(userList),1], initializer = tf.truncated_normal_initializer(stddev = 0.5))\n",
    "        predict += tf.matmul(user, betau)\n",
    "        tf.add_to_collection('losses', regularizer(betau))\n",
    "    \n",
    "    with tf.variable_scope('bi'):\n",
    "        betai = tf.get_variable(name = 'betai', shape = [len(businessList),1], initializer = tf.truncated_normal_initializer(stddev = 0.5))\n",
    "        predict += tf.matmul(business, betai)\n",
    "        tf.add_to_collection('losses', regularizer(betai))\n",
    "    \n",
    "    with tf.variable_scope('gamma'):\n",
    "        gammau = tf.get_variable(name = 'gu', shape = [len(userList), Reduction_Size], initializer = tf.truncated_normal_initializer(stddev = 0.5))\n",
    "        gammai = tf.get_variable(name = 'gi', shape = [Reduction_Size, len(businessList)], initializer = tf.truncated_normal_initializer(stddev = 0.5))\n",
    "        predict += tf.matmul(tf.matmul(user, gammau), tf.matmul(gammai, business.T))\n",
    "        tf.add_to_collection('losses', regularizer(gammau))\n",
    "        tf.add_to_collection('losses', regularizer(gammai))\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    U = tf.placeholder(tf.float32, [None, len(userList)], name = 'input-u')\n",
    "    B = tf.placeholder(tf.float32, [None, len(businessList)], name = 'input-b')\n",
    "    rating = tf.placeholder(tf.float32, [None], name = 'rating')\n",
    "    regularizer = tf.contrib.layers.l2_regularizer(regularization_rate)\n",
    "    \n",
    "    predict_ = calc(U,B,regularizer)\n",
    "    se = tf.losses.mean_squared_error(labels = rating, predictions = predict_)\n",
    "    sum_loss = tf.reduce_sum(se)\n",
    "    loss = sum_loss + tf.add_n(tf.get_collection('losses'))\n",
    "    \n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "        for i in range(max_iter):\n",
    "            sample = np.random.randint(0, 160000, batch_size)\n",
    "            x_batch = train_data[sample]\n",
    "            y_batch = train_rating[sample]\n",
    "            x_batch_feature = [feature(d) for d in x_batch]\n",
    "            x_batch_user = np.array([b[0] for b in x_batch_feature])\n",
    "            x_batch_business = np.array([b[1] for b in x_batch_feature])\n",
    "            \n",
    "            l_value, _ = sess.run([loss, train_op], fead_dict = {U:x_batch_user, B: x_batch_business, rating:y_batch})\n",
    "            if i % 1000 == 0:\n",
    "                print(\"After %d iters, loss on training batch is %f.\"%(i, l_value))\n",
    "                sample_ = np.random.randint(0, 40000, batch_size)\n",
    "                v_batch = validation_data[sample_]\n",
    "                v_rating = validation_rating[sample_]\n",
    "                v_batch_feature = [feature(d) for d in v_batch]\n",
    "                v_batch_user = np.array(v[0] for v in v_batch_feature)\n",
    "                v_batch_business = np.array(v[1] for v in v_batch_feature)\n",
    "                vl_value = sess.run(loss, feed_dict = {U:v_batch_user, B: v_batch_business, rating : v_rating})\n",
    "                print(\"After %d iters, loss on validation batch is %f\"%(i, vl_value))\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable bu/betau already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"<ipython-input-23-ed34b79082d2>\", line 4, in calc\n    betau = tf.get_variable(name = 'betau', shape = [len(userList),1], initializer = tf.truncated_normal_initializer(stddev = 0.5))\n  File \"<ipython-input-24-a3a8b1bbd2d1>\", line 7, in train\n    predict_ = calc(U,B,regularizer)\n  File \"<ipython-input-25-2da0ffaf5447>\", line 1, in <module>\n    train()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-2da0ffaf5447>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-27-a3a8b1bbd2d1>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mregularizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2_regularizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregularization_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpredict_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrating\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msum_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-5eff8bc3aaa0>\u001b[0m in \u001b[0;36mcalc\u001b[0;34m(user, business, regularizer)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavgRating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mbetau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'betau'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncated_normal_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'losses'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbetau\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m   1063\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m       use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m   1066\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1067\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    960\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m           use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m           validate_shape=validate_shape, use_resource=use_resource)\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    350\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m           use_resource=use_resource)\n\u001b[0m\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    662\u001b[0m                          \u001b[0;34m\" Did you mean to set reuse=True in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 664\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    665\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable bu/betau already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"<ipython-input-23-ed34b79082d2>\", line 4, in calc\n    betau = tf.get_variable(name = 'betau', shape = [len(userList),1], initializer = tf.truncated_normal_initializer(stddev = 0.5))\n  File \"<ipython-input-24-a3a8b1bbd2d1>\", line 7, in train\n    predict_ = calc(U,B,regularizer)\n  File \"<ipython-input-25-2da0ffaf5447>\", line 1, in <module>\n    train()\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
