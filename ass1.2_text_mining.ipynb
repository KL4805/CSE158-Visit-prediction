{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import gzip\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "import math\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'rating': 4.0, 'reviewHash': 'R567271252', 'businessID': 'B423621081', 'unixReviewTime': 1378865039, 'reviewText': u\"I'm a vegetarian, but every so often I want a hotdog with lots of toppings.  And a tall can of beer.  Frank has got that covered.  And they have a cool warehouse space with some pinball machines.  Prices are a little high for hotdogs...fancy hotdogs, but hotdogs nonetheless.  Good location and service, but gets crowded and loud.\", 'userID': 'U985379327', 'reviewTime': u'Sep 10, 2013', 'categories': [u'American Restaurant', u'Cafe', u'Hot Dog Restaurant'], 'categoryID': 0}, {'rating': 4.0, 'reviewHash': 'R985248711', 'businessID': 'B734024511', 'unixReviewTime': 1372977506, 'reviewText': u\"Asia Cafe is hands down the best Chinese food in Austin. Their menu has about 100 different options and it's really authentic. The spicy fish and the garlic pork are two of my favorites. It's a bit far from downtown Austin, right on the outskirts of Round Rock, but it's worth the drive.\", 'userID': 'U272385455', 'reviewTime': u'Jul 4, 2013', 'categories': [u'Chinese Restaurant', u'Asian Restaurant'], 'categoryID': 2}]\n"
     ]
    }
   ],
   "source": [
    "data = [l for l in readGz('train.json.gz')if 'categoryID' in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70195\n"
     ]
    }
   ],
   "source": [
    "print len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(string.punctuation)\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "#first try use stemmer\n",
    "stopword = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = defaultdict(int)\n",
    "for d in data:\n",
    "    review = ''.join(c for c in d['reviewText'].lower() if c not in punctuation)\n",
    "    wordList = review.split()\n",
    "    for w in wordList:\n",
    "        #w = stemmer.stem(w)\n",
    "        if w not in stopword:\n",
    "            wordCount[w] += 1\n",
    "#first try not using stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51283\n"
     ]
    }
   ],
   "source": [
    "print len(wordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = [(wordCount[w], w ) for w in wordCount]\n",
    "count.sort()\n",
    "count.reverse()\n",
    "\n",
    "commonWords = [count[i][1] for i in range(1000)]\n",
    "wordDict = defaultdict(int)\n",
    "for i in range(1000):\n",
    "    wordDict[commonWords[i]] = i\n",
    "\n",
    "#The 1000 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)\n",
    "train_label = [d['categoryID'] for d in data[:58000]]\n",
    "train_data = data[:58000]\n",
    "validation_label = [d['categoryID'] for d in data[58000:70195]]\n",
    "validation_data = data[58000:70195]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2523499189734044, 1.4176520594136381, 1.4451327026559233, 1.5799600253779253, 2.0678134213377324, 2.316861313794336, 2.385492978847886, 2.2712415982107252, 2.326152902128436, 2.419335824563028, 2.4826156654418363, 2.628330820965022, 2.626359600141428, 2.7631032584828534, 2.6725045853006995, 2.7476442298867907, 2.7708095522867744, 2.7689909566502977, 2.7843248192865695, 2.793127285203596, 2.8204874824174726, 2.9451087667833087, 2.952994599627237, 2.9510854213574356, 2.9226118351406605, 2.9645268526404105, 2.9829220201687106, 3.0357710432843055, 3.2317080020962576, 3.028384394245468, 2.98517490763243, 2.913647894285305, 3.094395886631829, 3.048304779431562, 3.1163328655084146, 3.0432126611947248, 3.054026824858805, 3.2823939014305887, 3.1800359915519367, 3.1513323495220265, 3.185187986461365, 3.204660089874185, 3.147677253244766, 3.209235146244199, 3.2767174434257837, 3.2669539411579325, 3.2624796607630113, 3.2706978616673976, 3.2850539828015504, 3.293460604721261, 3.3699919607485747, 3.3605093087808453, 3.275586008268312, 3.3187193790858873, 3.304263178906919, 3.3691638033513462, 3.4024090278671935, 3.4628197230596443, 3.377893852561036, 3.4452477458072965, 3.474708294724897, 3.396436313865982, 3.4528693922064764, 3.453319538511624, 3.4555733145388774, 3.463729227442485, 3.523728476146637, 3.6057457568056326, 3.524695126777732, 3.5280857815155926, 3.565658169284761, 3.5601319055346425, 3.5989518973842243, 3.563645083552079, 3.550161733214792, 3.590653094569529, 3.5079121867033516, 3.548179572010801, 3.537837199596207, 3.602081790393152, 3.6377143822068114, 3.703733876722761, 3.572228827243471, 3.541764548777705, 3.8305950095108896, 3.524695126777732, 3.5953126939916853, 3.609949651593766, 3.609949651593766, 3.9342789566380807, 3.6274799809987623, 3.650245191771775, 3.6453231145663465, 3.648601806028045, 3.6696202788973324, 3.710116259861851, 3.703733876722761, 3.680297536838177, 3.708952792598553, 3.911951777820295, 3.6876692742189543, 3.673540754375297, 3.681993890086355, 3.704891284259373, 3.7366586614192276, 3.723004546054203, 3.7265485544889323, 3.7688509341796217, 3.734867081364023, 3.7756642154136686, 3.856535938678726, 3.7682338406703755, 3.8444795300819714, 3.7159539880575365, 3.8451455307725895, 3.7932195251965797, 3.8572100202681194, 3.9006202118107454, 3.8162531730742058, 3.8852460445611574, 3.7888017205989706, 3.8156061332586844, 3.8391674325970815, 3.8136675219891827, 4.1176206986112405, 3.8755841336494203, 3.8491508765812648, 4.003636060509317, 4.1415262194647955, 3.9299184846127497, 3.83125182398442, 3.8831677618595193, 3.8943021844761843, 4.020959328361704, 4.005980727468572, 3.9676030323696723, 3.9091068256880637, 3.9006202118107454, 3.8845528036321806, 4.024938641213185, 3.931369863677397, 3.9212541704826087, 3.935007554120221, 3.9155193877405705, 4.042638218312587, 3.9371965371176025, 3.949692105803142, 3.9277453580784365, 3.9041475523287135, 4.079005862483461, 3.936466343583881, 4.16052272015545, 3.9827778303889074, 3.9556268413229567, 4.1176206986112405, 3.9889128189564236, 3.949692105803142, 4.032141553507244, 3.9997404576084867, 4.032945089106927, 4.010686618505984, 4.002855724925436, 4.045076252840016, 4.061483511791259, 4.032945089106927, 4.016204961244431, 4.092565392269094, 4.08745899819452, 4.0942733346142495, 4.242317342052442, 4.066458646431372, 4.0798479677963835, 4.139735708691007, 4.118495972190096, 4.07313089804044, 4.096840730119496, 4.127291103642923, 4.111515141048756, 4.153243343152549, 4.256289625247459, 4.151431748454199, 4.154150372693191, 4.163266206101201, 4.127291103642923, 4.17061918040646, 4.124644432490548, 4.114127245276681, 4.1696970964314914, 4.209175907405279, 4.109777521150215, 4.166935934990164, 4.16052272015545, 4.1167461904663085, 4.166017239473091, 4.214945154176524, 4.206303717781183, 4.154150372693191, 4.181751020775304, 4.304677860151029, 4.246289541912875, 4.178956421844289, 4.203439754009755, 4.234419966357492, 4.198684633304744, 4.3227730851289845, 4.192065223792068, 4.356637599081741, 4.213018371306824, 4.268423242258885, 4.246289541912875, 4.2393485125586405, 4.226584470833543, 4.2542815924442134, 4.2542815924442134, 4.269441054051586, 4.262338030783339, 4.281736290908623, 4.225609336675337, 4.297321021925321, 4.262338030783339, 4.367810899679866, 4.346687268228573, 4.283800275129474, 4.293141287522613, 4.288978950607926, 4.318485833117364, 4.282767750515285, 4.414973176094704, 4.364445781529552, 4.306789793354174, 4.332487138849458, 4.34339237233172, 4.395147453843617, 4.413796012921689, 4.330320290764368, 4.362208644131196, 4.319555924177209, 4.340108297130531, 4.332487138849458, 4.517850192665461, 4.402099973158498, 4.333572326150745, 4.398617671322624, 4.355527104797714, 4.395147453843617, 4.389390385553549, 4.366687934935242, 4.413796012921689, 4.4632334453475595, 4.339015997731921, 4.354417842343428, 4.396302855474172, 4.353309808989066, 4.38709680656645, 4.396302855474172, 4.419695735048878, 4.422065404404196, 4.932495693118586, 4.395147453843617, 4.414973176094704, 4.422065404404196, 4.44486183249658, 4.424440702433103, 4.4412276673823605, 4.616560401899247, 4.654744188869405, 4.471923754539537, 4.468190084987488, 4.448509252953623, 4.4819489011589155, 4.468190084987488, 4.466948619899424, 4.4819489011589155, 4.465708694136103, 4.411445835576735, 4.648774021882902, 4.612246951645528, 4.4819489011589155, 4.626698070183703, 4.473171415337692, 4.49717762186074, 4.519156528579516, 4.494623342055644, 4.6683088279035445, 4.479433176561669, 4.517850192665461, 4.513941392900407, 4.510047812381275, 4.647287032761324, 4.504879842222833, 4.5113439888427225, 4.581171004685005, 4.578393225121102, 4.510047812381275, 4.581171004685005, 4.55373444145785, 4.541629384431574, 4.65026322543437, 4.581171004685005, 4.5113439888427225, 4.596588268712332, 4.634002704562589, 4.568731314209366, 4.574240970020335, 4.639885074465656, 4.549683119238671, 4.616560401899247, 4.5632518484447395, 4.6325375028352616, 4.625243524472708, 4.628154734680167, 4.603675470595387, 4.656242316490428, 4.7891313795778245, 4.570105884872532, 4.592359932602811, 4.59941712491281, 4.605098958380241, 4.6310744447835015, 4.656242316490428, 4.575623140247287, 4.603675470595387, 4.6093816201722415, 4.638411234847355, 4.619446406788382, 4.629613524143826, 4.6325375028352616, 4.6093816201722415, 4.654744188869405, 4.619446406788382, 4.691333636301698, 4.677455233129621, 4.612246951645528, 4.63547005625654, 4.634002704562589, 4.682059999516369, 4.683599645701961, 4.6789878004793986, 4.8328828892509526, 4.647287032761324, 4.750503571346553, 4.895634099814428, 4.72128071266965, 4.672871573461962, 4.680522720197482, 4.806402966086485, 4.699127908028517, 4.8564133866611465, 4.827530512512361, 4.714901105705611, 4.734163338500664, 4.7022627068338885, 4.680522720197482, 4.7925619146746135, 4.876765615510045, 4.722881994036624, 4.825752734266361, 4.680522720197482, 4.7309270897214555, 5.012703104737154, 4.72128071266965, 4.748857480439884, 4.757115165678866, 4.755458164471237, 4.75380390437521, 4.757115165678866, 4.7891313795778245, 4.960553645913744, 4.7704709568604216, 4.773837963408326, 4.8186730586783, 4.806402966086485, 4.762102707189905, 4.962588234611531, 4.8328828892509526, 4.763770764290602, 4.742300079893726, 4.734163338500664, 4.936456094334683, 4.763770764290602, 4.7925619146746135, 4.775525727522046, 4.886155355859884, 4.7704709568604216, 4.7908451760555595, 4.8239781109079924, 4.780606178754465, 4.907128479240163, 4.775525727522046, 4.86561308355957, 4.808146645691312, 4.778909825506286, 4.836467122478767, 5.081390119057017, 4.845484316128957, 4.909057120146569, 4.845484316128957, 4.916809096950886, 4.871173802244267, 4.867463222847731, 4.8328828892509526, 4.8937311496683416, 4.8619230424721165, 4.850933920896521, 4.938442192306312, 4.912925596924489, 4.962588234611531, 4.983165092300291, 4.852757075458036, 4.952456435681124, 4.8937311496683416, 4.891831813864689, 5.054239129991067, 4.8994508983411285, 4.8600831155501085, 4.912925596924489, 4.88993607869979, 4.886155355859884, 4.999936973914119, 4.89754067808501, 4.878636523445857, 4.878636523445857, 4.895634099814428, 4.905203550830579, 4.912925596924489, 4.954474599837361, 4.884270341164113, 4.954474599837361, 5.029982152345506, 4.966669872931179, 5.063207799973827, 5.021305308319818, 4.903282320652685, 4.956496845218129, 4.962588234611531, 4.907128479240163, 4.910989487897623, 4.932495693118586, 4.940432242714323, 4.966669872931179, 4.930521358814868, 5.043140236923017, 4.958523188363362, 4.936456094334683, 5.369072191508798, 5.0609580802398115, 4.930521358814868, 5.019147810179796, 5.052009474663797, 4.960553645913744, 5.021305308319818, 5.019147810179796, 5.006299667701947, 4.999936973914119, 5.012703104737154, 4.9810882483554515, 4.99571755837141, 4.989421629914595, 5.063207799973827, 4.99151587151771, 4.974883471468568, 4.99151587151771, 5.021305308319818, 5.090606774161941, 4.99151587151771, 4.989421629914595, 5.0084295939597725, 5.006299667701947, 5.002053376820497, 4.985246258504115, 4.9769474556894195, 5.025634319409403, 5.092924272302303, 4.99571755837141, 5.069987486959206, 5.102248349177427, 5.049784779641686, 5.11639952872367, 5.095247153718444, 5.261878494769311, 5.040935164364703, 5.195453018787606, 5.111660183359773, 5.063207799973827, 5.208389809818325, 5.090606774161941, 5.063207799973827, 5.038734943455101, 5.058713410385987, 5.04535018257382, 5.104593016136681, 5.081390119057017, 5.065462592360916, 5.088294634403562, 5.264629528141201, 5.043140236923017, 5.067722480328354, 5.104593016136681, 5.04535018257382, 5.076813452029605, 5.097575443478035, 5.04535018257382, 5.275709973917773, 5.102248349177427, 5.25913500882356, 5.0836863313173675, 5.076813452029605, 5.172580357121614, 5.11639952872367, 5.1069431934816345, 5.118777651128638, 5.11402704837004, 5.063207799973827, 5.072257635493744, 5.088294634403562, 5.229443219016157, 5.099909166824255, 5.229443219016157, 5.128347102144788, 5.0836863313173675, 5.1069431934816345, 5.208389809818325, 5.111660183359773, 5.140439147909817, 5.150219176963456, 5.102248349177427, 5.111660183359773, 5.33894943205369, 5.1928856232823595, 5.160095800459368, 5.157617484444901, 5.18014659750493, 5.1453172063632495, 5.058713410385987, 5.165070935099482, 5.2162329872793505, 5.26738815058028, 5.240138508132905, 5.104593016136681, 5.205789028118267, 5.150219176963456, 5.12594614060725, 5.25913500882356, 5.157617484444901, 5.25913500882356, 5.256399029004685, 5.20060766937627, 5.335986466923033, 5.14776518800189, 5.165070935099482, 5.2897354492722775, 5.142875202707698, 5.198027022782778, 5.175096081718861, 5.177618151151571, 5.221496157323625, 5.177618151151571, 5.221496157323625, 5.20060766937627, 5.190324802420686, 5.224138166786464, 5.20060766937627, 5.203194992941221, 5.205789028118267, 5.234776564991519, 5.321301915240111, 5.195453018787606, 5.1928856232823595, 5.170070945516188, 5.1877705226155895, 5.18014659750493, 5.175096081718861, 5.195453018787606, 5.198027022782778, 5.237453942762236, 5.461938875900647, 5.240138508132905, 5.1928856232823595, 5.203194992941221, 5.372134981039344, 5.292564305472755, 5.347891369429351, 5.221496157323625, 5.2897354492722775, 5.226787174958041, 5.298246138940186, 5.248235718365525, 5.25094942423712, 5.264629528141201, 5.275709973917773, 5.384480816861643, 5.2897354492722775, 5.205789028118267, 5.25094942423712, 5.281296580626413, 5.25094942423712, 5.264629528141201, 5.237453942762236, 5.240138508132905, 5.264629528141201, 5.286914572930636, 5.253670514351481, 5.350889872425608, 5.264629528141201, 5.359939707945526, 5.303960440203625, 5.275709973917773, 5.253670514351481, 5.275709973917773, 5.335986466923033, 5.275709973917773, 5.327149885122535, 5.270154404073171, 5.387591239276036, 5.286914572930636, 5.281296580626413, 5.281296580626413, 5.25913500882356, 5.47545259506737, 5.330086744795844, 5.278499376005351, 5.309707582459192, 5.335986466923033, 5.261878494769311, 5.3154879453746915, 5.333032255025602, 5.298246138940186, 5.2897354492722775, 5.301099207922592, 5.327149885122535, 5.312593587348327, 5.3449018305809854, 5.347891369429351, 5.353897393489563, 5.409639376497799, 5.330086744795844, 5.333032255025602, 5.306829882631577, 5.375207180076314, 5.393841259621207, 5.3419212024428475, 5.353897393489563, 5.350889872425608, 5.333032255025602, 5.335986466923033, 5.353897393489563, 5.281296580626413, 5.448605345031182, 5.448605345031182, 5.330086744795844, 5.416029174596569, 5.384480816861643, 5.3660187540219075, 5.381380039183395, 5.324221625343446, 5.396980979625875, 5.301099207922592, 5.327149885122535, 5.409639376497799, 5.387591239276036, 5.393841259621207, 5.369072191508798, 5.387591239276036, 5.369072191508798, 5.384480816861643, 5.356913987028989, 5.412829171865899, 5.369072191508798, 5.350889872425608, 5.36297461164068, 5.425691085508306, 5.378288846613723, 5.458588789015365, 5.375207180076314, 5.435447260453671, 5.409639376497799, 5.375207180076314, 5.400130588528771, 5.384480816861643, 5.387591239276036, 5.396980979625875, 5.412829171865899, 5.637571444543805, 5.492605674293619, 5.406459723580419, 5.416029174596569, 5.396980979625875, 5.455249887749851, 5.445299556896682, 5.347891369429351, 5.43872058579864, 5.393841259621207, 5.4224600649268595, 5.478859753388984, 5.36297461164068, 5.425691085508306, 5.560610403407677, 5.54226126473948, 5.425691085508306, 5.451922097657176, 5.670094636249365, 5.400130588528771, 5.653700826473689, 5.48227856013777, 5.43872058579864, 5.428932579432477, 5.553230296110054, 5.44200466099983, 5.503040551586199, 5.489151439425532, 5.455249887749851, 5.468672908081992, 5.465300223603352, 5.445299556896682, 5.617768817247625, 5.503040551586199, 5.48227856013777, 5.524242759236802, 5.57930253641983, 5.520677693072305, 5.496071882270106, 5.510058124244845, 5.485709095234559, 5.4720570060662315, 5.535014856218713, 5.568045381895195, 5.468672908081992, 5.496071882270106, 5.489151439425532, 5.4720570060662315, 5.448605345031182, 5.633579423274268, 5.682568810474541, 5.513585464762814, 5.492605674293619, 5.503040551586199, 5.8458263833642645, 5.54226126473948, 5.48227856013777, 5.492605674293619, 5.538631496688901, 5.531411248715415, 5.49955014664643, 5.602204300706513, 5.575536053624353, 5.545904256017981, 5.657774151861324, 5.506543182137401, 5.553230296110054, 5.517125291467938, 5.598350731390524, 5.527820580584686, 5.602204300706513, 5.538631496688901, 5.575536053624353, 5.641579465941344, 5.751860590945933, 5.6618641371128495, 5.564320982804213, 5.617768817247625, 5.535014856218713, 5.594511955083358, 5.571783704005802, 5.609956277510832, 5.590687858644955, 5.564320982804213, 5.553230296110054, 5.617768817247625, 5.629603274894628, 5.609956277510832, 5.594511955083358, 5.625642873678531, 5.720953053482856, 5.571783704005802, 5.606072777484434, 5.590687858644955, 5.568045381895195, 5.625642873678531, 5.609956277510832, 5.560610403407677, 5.670094636249365, 5.649644025778074, 5.556913541526351, 5.729686733451611, 5.69097222127092, 5.594511955083358, 5.707993908840351, 5.606072777484434, 5.556913541526351, 5.625642873678531, 5.665970919065503, 5.665970919065503, 5.583083259259736, 5.545904256017981, 5.553230296110054, 5.621698095387515, 5.657774151861324, 5.621698095387515, 5.657774151861324, 5.602204300706513, 5.674235428915397, 5.625642873678531, 5.641579465941344, 5.653700826473689, 5.625642873678531, 5.720953053482856, 5.695200557380441, 5.686761688734577, 5.645603616241069, 5.665970919065503, 5.699446848261893, 5.602204300706513, 5.6618641371128495, 5.641579465941344, 5.699446848261893, 5.712294990739742, 5.629603274894628, 5.682568810474541, 5.670094636249365, 5.621698095387515, 5.707993908840351, 5.670094636249365, 5.629603274894628, 5.682568810474541, 5.779135008865592, 5.657774151861324, 5.70371124704835, 5.70371124704835, 5.707993908840351, 5.665970919065503, 5.598350731390524, 5.633579423274268, 5.716614651884258, 5.695200557380441, 5.734082344924649, 5.6618641371128495, 5.6618641371128495, 5.682568810474541, 5.720953053482856, 5.712294990739742, 5.649644025778074, 5.917285347346409, 5.665970919065503, 5.629603274894628, 5.637571444543805, 5.707993908840351, 5.725310358851812, 5.70371124704835, 5.807174228929985, 5.695200557380441, 5.637571444543805, 5.811924831688583, 5.707993908840351, 5.76540481605369, 5.797740196696626, 5.7429319602016315, 5.720953053482856, 5.720953053482856, 5.686761688734577, 5.699446848261893, 5.637571444543805, 5.712294990739742, 5.729686733451611, 5.712294990739742, 5.6783934390640605, 5.734082344924649, 5.734082344924649, 5.788394334278389, 5.716614651884258, 5.729686733451611, 5.840912368561835, 5.69097222127092, 5.69097222127092, 5.70371124704835, 5.716614651884258, 5.747386310551012, 5.699446848261893, 5.720953053482856, 5.712294990739742, 5.695200557380441, 5.6618641371128495, 5.682568810474541, 5.712294990739742, 5.7384973631337655, 5.850764665004847, 5.7930563473842005, 5.7384973631337655, 5.734082344924649, 5.670094636249365, 5.760869660888299, 5.712294990739742, 5.7384973631337655, 5.756354980533772, 5.811924831688583, 5.8458263833642645, 5.7384973631337655, 5.7930563473842005, 5.695200557380441, 5.865727537681559, 5.716614651884258, 5.747386310551012, 5.716614651884258, 5.729686733451611, 5.779135008865592, 5.720953053482856, 5.747386310551012, 5.821494282704734, 5.797740196696626, 5.720953053482856, 5.788394334278389, 5.779135008865592, 5.797740196696626, 5.807174228929985, 5.821494282704734, 5.729686733451611, 5.774537299616963, 5.779135008865592, 5.725310358851812, 5.788394334278389, 5.836022383267643, 5.875828633668063, 5.880917703175535, 5.769960632589551, 5.729686733451611, 5.807174228929985, 5.7429319602016315, 5.840912368561835, 5.769960632589551, 5.840912368561835, 5.821494282704734, 5.840912368561835, 5.807174228929985, 5.76540481605369, 5.860714995858015, 5.880917703175535, 5.938676537327726, 5.8911742033427235, 5.734082344924649, 5.8458263833642645, 6.059165934581853, 5.756354980533772, 5.8707653317115165, 5.836022383267643, 5.779135008865592, 5.756354980533772, 5.826313569140683, 5.7930563473842005, 5.807174228929985, 5.8707653317115165, 5.779135008865592, 5.797740196696626, 5.917285347346409, 5.769960632589551, 5.797740196696626, 5.855727454346976, 5.783753954721886, 5.880917703175535, 5.821494282704734, 5.797740196696626, 5.816698110441241, 5.860714995858015, 5.816698110441241, 5.938676537327726, 5.875828633668063, 5.977248812113967, 5.802446087734039, 5.811924831688583, 5.802446087734039, 5.807174228929985, 5.8911742033427235, 5.988548367367899, 5.906758934359422, 5.865727537681559, 6.011537885592598, 5.880917703175535, 5.826313569140683, 5.811924831688583, 5.8458263833642645, 5.896342173501166, 5.960535331140226, 5.944096604797066, 5.865727537681559, 5.8911742033427235, 5.83115619361647, 5.93328568869285, 5.8458263833642645, 5.7930563473842005, 5.999977063191523, 5.875828633668063, 5.8911742033427235, 5.875828633668063, 5.855727454346976, 5.906758934359422, 5.8707653317115165, 5.8911742033427235, 5.94954620956463, 5.8458263833642645, 5.906758934359422, 6.005740767908272, 5.90153699037827]\n"
     ]
    }
   ],
   "source": [
    "#calculate tf-idf\n",
    "#tf can be calculated when extracting feature\n",
    "#idf calculated here\n",
    "idf = [0 for i in range(1000)]\n",
    "for d in train_data:\n",
    "    review = ''.join(c for c in d['reviewText'].lower() if c not in punctuation)\n",
    "    wordList = review.split()\n",
    "    for w in commonWords:\n",
    "        if w in wordList:\n",
    "            idf[wordDict[w]] += 1.0\n",
    "            \n",
    "idf = np.array([math.log(70195.0/f) for f in idf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(datum):\n",
    "    #count tf-idf\n",
    "    review = ''.join(c for c in d['reviewText'].lower() if c not in punctuation)\n",
    "    wordList = review.split()\n",
    "    tf = [0 for i in range(1000)]\n",
    "    for w in wordList:\n",
    "        if w in commonWords:\n",
    "            tf[wordDict[w]] += 1.0\n",
    "    tf = np.array(tf)\n",
    "    tfidf = np.multiply(tf,idf)\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = np.array([feature(d) for d in train_data])\n",
    "validation_feature = np.array([feature(d) for d in validation_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_size = 300\n",
    "input_size = 1000\n",
    "output_size = 10\n",
    "regularization_rate = 0.0001\n",
    "learning_rate = 0.00001\n",
    "batch_size = 200\n",
    "max_iter = 60000\n",
    "#tensorflow learning hyperpatameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(X, regularizer):\n",
    "    with tf.variable_scope('fc1'):\n",
    "        w1 = tf.get_variable(name = 'weight', shape = [input_size, fc_size], initializer = tf.truncated_normal_initializer(stddev = 0.1))\n",
    "        b1 = tf.get_variable(name = 'bias', shape = [fc_size], initializer = tf.constant_initializer(0.1))\n",
    "        fc1 = tf.nn.relu(tf.matmul(X, w1)+b1)\n",
    "        tf.add_to_collection('losses', regularizer(w1))\n",
    "    \n",
    "    with tf.variable_scope('fc2'):\n",
    "        w2 = tf.get_variable(name = 'weight', shape = [fc_size, output_size], initializer = tf.truncated_normal_initializer(stddev = 0.1))\n",
    "        b2 = tf.get_variable(name = 'bias', shape = [output_size], initializer = tf.constant_initializer(0.1))\n",
    "        fc2 = tf.matmul(fc1, w2) + b2\n",
    "        tf.add_to_collection('losses', regularizer(w2))\n",
    "    \n",
    "    return fc2\n",
    "#A neural network with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    X = tf.placeholder(tf.float64, [None, input_size], name = 'input-X')\n",
    "    y = tf.placeholder(tf.int64, [None], name = 'input-Y')\n",
    "    \n",
    "    regularizer = tf.contrib.layers.l2_regularizer(regularization_rate)\n",
    "    \n",
    "    y_ = calc(X, regularizer)\n",
    "    y_predict = tf.argmax(y_,1)\n",
    "    correct_prediction = tf.cast(tf.equal(y_predict, y),tf.float32)\n",
    "    accuracy = tf.reduce_mean(correct_prediction)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = y_, labels = y)\n",
    "    loss = cross_entropy + tf.add_n(tf.get_collection('losses'))\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        tf.initialize_all_variables().run()\n",
    "        for i in range(max_iter):\n",
    "            sample = np.random.randint(0, 58000, batch_size)\n",
    "            x_batch = train_data[sample]\n",
    "            y_batch = train_label[sample]\n",
    "            \n",
    "            _, loss_value = sess.run([train_step, loss], feed_dict = {X:x_batch,y:y_batch})\n",
    "            if i % 1000 == 0:\n",
    "                print(\"After %d iters, loss on training is %f.\"%(i, loss_value))\n",
    "                acc = sess.run(accuracy, feed_dict = {X:validation_feature, y:validation_label})\n",
    "                print(\"After %d iters, accuracy on validation is %f\"%(i, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
