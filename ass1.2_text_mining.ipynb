{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import gzip\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(f):\n",
    "    for l in gzip.open(f):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [l for l in readGz('train.json.gz')if 'categoryID' in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70195\n"
     ]
    }
   ],
   "source": [
    "print len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = set(string.punctuation)\n",
    "stemmer = nltk.stem.porter.PorterStemmer()\n",
    "#first try use stemmer\n",
    "stopword = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = defaultdict(int)\n",
    "for d in data:\n",
    "    review = ''.join(c for c in d['reviewText'].lower() if c not in punctuation)\n",
    "    wordList = review.split()\n",
    "\n",
    "    wordList = [stemmer.stem(w) for w in wordList if w not in stopword]\n",
    "    d['wordList'] = wordList\n",
    "    for w in wordList:\n",
    "        wordCount[w] += 1\n",
    "#use stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39909\n"
     ]
    }
   ],
   "source": [
    "print len(wordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenWords = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = [(wordCount[w], w ) for w in wordCount]\n",
    "count.sort()\n",
    "count.reverse()\n",
    "\n",
    "commonWords = [t[1] for t in count[:lenWords]]\n",
    "\n",
    "wordDict = defaultdict(int)\n",
    "for i in range(lenWords):\n",
    "    wordDict[commonWords[i]] = i\n",
    "\n",
    "#The 1000 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(data)\n",
    "train_label = np.array([d['categoryID'] for d in data[:60000]])\n",
    "train_data = data[:60000]\n",
    "validation_label = np.array([d['categoryID'] for d in data[60000:70195]])\n",
    "validation_data = data[60000:70195]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#calculate idf\n",
    "#tf calculated when creating feature\n",
    "idf = [0 for i in range(lenWords)]\n",
    "\n",
    "for d in train_data:\n",
    "    reviewSet = set(d['wordList'])\n",
    "    for w in commonWords:\n",
    "        if w in reviewSet:\n",
    "            idf[wordDict[w]] += 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = [math.log(60000/f) for f in idf]\n",
    "idf = np.array(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgRating = np.mean([d['rating'] for d in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "userList = []\n",
    "businessList = []\n",
    "for d in train_data:\n",
    "    if d['userID'] not in userList:\n",
    "        userList.append(d['userID'])\n",
    "    if d['businessID'] not in businessList:\n",
    "        businessList.append(d['businessID'])\n",
    "userDict = defaultdict(int)\n",
    "businessDict = defaultdict(int)\n",
    "for i in range(len(userList)):\n",
    "    userDict[userList[i]] = i\n",
    "for i in range(len(businessList)):\n",
    "    businessDict[businessList[i]] = i\n",
    "userHistory = [[0 for i in range(10)] for j in range(len(userList))]\n",
    "userCatRating = [[[] for i in range(10)]for u in userList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#building lists of user's visited businesses\n",
    "u_visited = [defaultdict(float) for u in userList]\n",
    "b_visited = [defaultdict(float) for b in businessList]\n",
    "for d in train_data:\n",
    "    u = userDict[d['userID']]\n",
    "    b = businessDict[d['businessID']]\n",
    "    rating = d['rating']\n",
    "    u_visited[u][b] = rating\n",
    "    b_visited[b][u] = rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get average rating of all businesses and all users\n",
    "userAvg = [np.mean([u_visited[u][t] for t in u_visited[u]]) for u in range(len(userList))]\n",
    "businessAvg = [np.mean([b_visited[b][t] for t in b_visited[b]]) for b in range(len(businessList))]\n",
    "avgRating = np.mean([d['rating'] for d in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uJaccard(u1, u2):\n",
    "    u1Set = set([b for b in u_visited[u1]])\n",
    "    u2Set = set([b for b in u_visited[u2]])\n",
    "    return (len(u1Set & u2Set)*1.0)/len(u1Set | u2Set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uPearson(u1,u2):\n",
    "    u1Set = set([b for b in u_visited[u1]])\n",
    "    u2Set = set([b for b in u_visited[u2]])\n",
    "    u1rList = []\n",
    "    u2rList = []\n",
    "    bavg = []\n",
    "    for b in (u1Set & u2Set):\n",
    "        u1rList.append(u_visited[u1][b])\n",
    "        u2rList.append(u_visited[u2][b])\n",
    "        bavg.append(businessAvg[b])\n",
    "\n",
    "    if len(u1Set & u2Set) != 0:\n",
    "        cov = np.sum([(u1rList[i]-bavg[i])*(u2rList[i]-bavg[i]) for i in range(len(u1rList))])\n",
    "        std = math.sqrt(np.sum([(r-a)**2 for r,a in zip(u1rList, bavg)]) * np.sum(([(r-a)**2 for r,a in zip(u2rList, bavg)])))\n",
    "        return (cov*1.0)/std if std != 0 else 0\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in train_data:\n",
    "    u = userDict[d['userID']]\n",
    "    c = d['categoryID']\n",
    "    userCatRating[u][c].append(d['rating'])\n",
    "    userHistory[u][c]+=1.0\n",
    "userCatAvg = [[np.mean(l)-userAvg[u] if len(l)!=0 else 0 for l in userCatRating[u] ]for u in range(len(userList))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "userHistory = [np.divide(u, np.linalg.norm(u)) for u in userHistory]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat(datum):\n",
    "    wordList = datum['wordList']\n",
    "    tf = [0 for i in range(lenWords)]\n",
    "    for w in wordList:\n",
    "        if w in commonWords:\n",
    "            tf[wordDict[w]] += 1.0\n",
    "    tf = np.array(tf)\n",
    "    if np.max(tf) != 0 :\n",
    "        tf = np.divide(tf, np.max(tf))\n",
    "    tfidf = np.multiply(tf, idf)\n",
    "    if datum['userID'] in userList:\n",
    "        u = userDict[datum['userID']]\n",
    "        tfidf = np.concatenate((tfidf, userHistory[u]))\n",
    "        tfidf = np.concatenate((tfidf, userCatAvg[u]))\n",
    "    else:\n",
    "        tfidf = np.concatenate((tfidf, [0 for i in range(20)]))\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = np.array([feat(d) for d in train_data])\n",
    "validation_feature = np.array([feat(d) for d in validation_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 2020)\n"
     ]
    }
   ],
   "source": [
    "print np.shape(train_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tfidf = [[]for i in range(10)]\n",
    "for f, l in zip(train_feature, train_label):\n",
    "    avg_tfidf[l].append(f[0:lenWords])\n",
    "avg_tfidf = [np.mean(v, 0) for v in avg_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2000)\n"
     ]
    }
   ],
   "source": [
    "print np.shape(avg_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(f):\n",
    "    if np.linalg.norm(f[:2000]) !=0:\n",
    "        f = np.concatenate((f, [cosine(f[:2000], avg_tfidf[i]) for i in range(10)]))\n",
    "    else:\n",
    "        f = np.concatenate((f, [0 for i in range(10)]))\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature = np.array([feature(d) for d in train_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 2030)\n"
     ]
    }
   ],
   "source": [
    "print np.shape(train_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "for l in readGz(\"test_Category.json.gz\"):\n",
    "    test_data.append(l)\n",
    "for d in test_data:\n",
    "\n",
    "    review = ''.join(c for c in d['reviewText'].lower() if c not in punctuation)\n",
    "    wordList = review.split()\n",
    "    wordList = [stemmer.stem(w) for w in wordList if w not in stopword]\n",
    "    d['wordList'] = wordList\n",
    "test_feature = np.array([feat(d) for d in test_data])\n",
    "test_feature = np.array([feature(d) for d in test_feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_feature = [feature(d) for d in validation_feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_size = 500\n",
    "input_size = 2030\n",
    "output_size = 10\n",
    "regularization_rate = 0.001\n",
    "learning_rate = 0.001\n",
    "batch_size = 200\n",
    "max_iter = 60000\n",
    "#tensorflow learning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc(X, regularizer):\n",
    "    with tf.variable_scope('fc1'):\n",
    "        w1 = tf.get_variable(name = 'weight', shape = [input_size, output_size], initializer = tf.truncated_normal_initializer(stddev = 0.1))\n",
    "        b1 = tf.get_variable(name = 'bias', shape = [output_size], initializer = tf.constant_initializer(0.1))\n",
    "        #fc1 = tf.nn.relu(tf.matmul(X, w1)+b1)\n",
    "        fc1 = tf.matmul(X, w1)+b1\n",
    "        tf.add_to_collection('losses', regularizer(w1))\n",
    "    \n",
    "    '''with tf.variable_scope('fc2'):\n",
    "        w2 = tf.get_variable(name = 'weight', shape = [fc_size, output_size], initializer = tf.truncated_normal_initializer(stddev = 0.1))\n",
    "        b2 = tf.get_variable(name = 'bias', shape = [output_size], initializer = tf.constant_initializer(0.1))\n",
    "        fc2 = tf.matmul(fc1, w2) + b2\n",
    "        tf.add_to_collection('losses', regularizer(w2))'''\n",
    "    \n",
    "    return fc1\n",
    "#A neural network with one hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, input_size], name = 'input-X')\n",
    "y = tf.placeholder(tf.int64, [None], name = 'input-Y')\n",
    "    \n",
    "regularizer = tf.contrib.layers.l2_regularizer(regularization_rate)\n",
    "    \n",
    "y_ = calc(X, regularizer)\n",
    "y_predict = tf.argmax(y_,1)\n",
    "correct_prediction = tf.cast(tf.equal(y_predict, y),tf.float32)\n",
    "accuracy = tf.reduce_mean(correct_prediction)\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = y_, labels = y)\n",
    "loss = tf.reduce_mean(cross_entropy) + tf.add_n(tf.get_collection('losses'))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/util/tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "After 0 iters, loss on training is 2.989082.\n",
      "After 0 iters, accuracy on validation is 0.069936\n",
      "After 500 iters, loss on training is 1.225639.\n",
      "After 500 iters, accuracy on validation is 0.582344\n",
      "After 1000 iters, loss on training is 0.944804.\n",
      "After 1000 iters, accuracy on validation is 0.614321\n",
      "After 1500 iters, loss on training is 0.951435.\n",
      "After 1500 iters, accuracy on validation is 0.613144\n",
      "After 2000 iters, loss on training is 0.800645.\n",
      "After 2000 iters, accuracy on validation is 0.605787\n",
      "After 2500 iters, loss on training is 0.933409.\n",
      "After 2500 iters, accuracy on validation is 0.599117\n",
      "After 3000 iters, loss on training is 0.911310.\n",
      "After 3000 iters, accuracy on validation is 0.590387\n",
      "After 3500 iters, loss on training is 0.754650.\n",
      "After 3500 iters, accuracy on validation is 0.587052\n",
      "After 4000 iters, loss on training is 0.759172.\n",
      "After 4000 iters, accuracy on validation is 0.580481\n",
      "After 4500 iters, loss on training is 0.841385.\n",
      "After 4500 iters, accuracy on validation is 0.572634\n",
      "After 5000 iters, loss on training is 0.780013.\n",
      "After 5000 iters, accuracy on validation is 0.570770\n",
      "After 5500 iters, loss on training is 0.987259.\n",
      "After 5500 iters, accuracy on validation is 0.567729\n",
      "After 6000 iters, loss on training is 0.948725.\n",
      "After 6000 iters, accuracy on validation is 0.569103\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-1c1637fed9ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m60000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_feature\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    for i in range(max_iter):\n",
    "        sample = np.random.randint(0, 60000, batch_size)\n",
    "        x_batch = train_feature[sample]\n",
    "        y_batch = train_label[sample]\n",
    "            \n",
    "        _, loss_value = sess.run([train_step, loss], feed_dict = {X:x_batch,y:y_batch})\n",
    "        if i % 500 == 0:\n",
    "            print(\"After %d iters, loss on training is %f.\"%(i, loss_value))\n",
    "            acc = sess.run(accuracy, feed_dict = {X:validation_feature, y:validation_label})\n",
    "            print(\"After %d iters, accuracy on validation is %f\"%(i, acc))\n",
    "    predictions = open(\"predictions_Category.txt\", 'w')\n",
    "    predictions.write(\"userID-reviewHash,category\\n\")\n",
    "    y_p = sess.run(y_predict, feed_dict = {X : test_feature,dropout_r:1})\n",
    "    for d, l in zip(test_data, y_p):\n",
    "        predictions.write(d['userID'] + '-' + d['reviewHash'] + ',' + str(l) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
